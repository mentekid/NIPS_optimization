\documentclass{article}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{array}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{wasysym}
\usepackage{tabularx}
\usepackage{threeparttable}
\usepackage{listings}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2017
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2017}

\usepackage[]{nips_2017}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2017}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\newcommand*\rot{\rotatebox{90}}
\newcommand*\OK{\ding{51}}

% Could this be a better title?
\title{A generic and fast C++ optimization framework}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Shikhar Bhardwaj \\
  \AND
  Yannis Mentekidis \\
  \AND
  Marcus Edel \\
  Free University of Berlin \\
  Arnimallee 7, 14195 Berlin \\
  \texttt{marcus.edel@fu-berlin.de} \\
  \AND
  Ryan R. Curtin \\
  Symantec Corporation \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
The development of the {\bf mlpack} C++ machine learning library
(\url{http://www.mlpack.org/}) has required the design and implementation of a
flexible, robust optimization system that is able to solve the types of
arbitrary optimization problems that may arise all throughout machine learning
problems.  You care because:

\begin{itemize}
  \item It's easy to implement new optimizers.
  \item It's easy to implement new functions to be optimized.
  \item This system is more comprehensive than other techniques that may focus
only on neural networks or single problems.
  \item This system is also more specific and offers more room for optimization
than super general systems like scipy.optimize().
\end{itemize}

This abstract will need to be rewritten.
\end{abstract}

\section{Introduction}

Machine learning is a field that is inextricably intertwined with the field of
optimization.  Countless machine learning techniques depend on the optimization
of a given objective function; for instance, classifiers such as logistic
regression \cite{cox1958regression}, metric learning methods like NCA
\cite{goldberger2005neighbourhood}, manifold learning algorithms like MVU
\cite{weinberger2006introduction}, and the extremely popular field of deep
learning \cite{schmidhuber2015deep}.  Thanks to the attention focused on these
problems, it is increasingly important in the field to have fast, practical
optimizers.  This can explain the current focus on optimization: this year at
ICML (2017), every single session had at least one track devoted solely to
optimization techniques.

Therefore, the need is real to provide a robust, flexible framework in which
new optimizers can be easily developed.  Similarly, the need is also real for a
flexible framework that allows new objective functions to be easily implemented
and optimized with a variety of possible optimizers.

However, the current landscape of optimization frameworks for machine learning
is not particularly comprehensive.  A variety of tools such as
Caffe \cite{jia2014caffe},
% mxnet ??
TensorFlow \cite{abadi2016tensorflow},
and
Keras \cite{chollet2015}
have optimization frameworks, but they are limited to SGD-type optimizers and
only are able to optimize deep neural networks or related structures.  Thus
expressing arbitrary machine learning objective functions can be difficult or in
some cases not possible.  Other libraries, like
% Shogun \cite{shogun}
%and
scikit-learn \cite{pedregosa2011scikit},
do have optimizers implementation, but generally not in a coherent framework and
often the implementations may be specific to an individual machine learning
algorithm.  At a higher level, many programming languages may have generic
optimizers, like SciPy \cite{jones2014scipy} and MATLAB, but typically these
optimizers are not suitable for large-scale machine learning tasks where, e.g.,
calculating the full gradient of all of the data may not be feasible.

Given this situation, we have developed a flexible optimization infrastructure
in the {\bf mlpack} C++ machine learning library \cite{mlpack2013}.  This
infrastructure makes it easy to combine nearly any type of optimizer with nearly
any type of objective function, and has allowed us to minimize the effort
necessary to both implement new optimizers and to implement new machine learning
algorithms that depend on optimization.  Since the framework is implemented in
C++ and uses template metaprogramming, we are able to preserve a clean syntax
while simultaneously allowing compile-time optimizations that can result in a
generic optimizer that is equivalently fast to an optimizer written specifically
for one objective function.

In this short paper, we describe mlpack's optimization infrastructure in detail.
First, we describe the types of optimization problems we would like to solve,
which then allows us to build a generic and intuitive API for objective
functions to implement and optimizers to depend upon.  We show a very simple
example objective function and optimizer, and a system that we have built to
detect when a user passes an objective function that cannot be optimized by a
certain optimizer.  Lastly, we show the optimizers we have implemented in this
framework, and some example usage of mlpack's optimizers.

%In recent times, machine learning conferences have focused more and more on
%optimization techniques.  For instance, this year at ICML (ICML 2017), every
%single session had at least one track devoted solely to optimization
%techniques.
%<TODO: add some more filler here.  Show that optimization is an important part
%of machine learning, in whatever ways.>

%\begin{itemize}
%  \item This sequence of events (or situation) motivates the development of a
%generic, flexible, and fast optimization framework.
%  \item We have implemented exactly this in {\bf mlpack}, and it's good.
%\end{itemize}

%{\bf <TODO: elaborate on above, add a few more sentences.>}

%{\bf <TODO: mention related work, or really that we haven't found other
%libraries that have a comprehensive infrastructure like the one we have built,
%and that what we have built is more flexible and generic}

% Just to get a feeling of the look; Also, we could also just use \OK instead of \CURCLE or \LEFTcircle
\begin{table}
\centering
    \begin{tabular}{@{} cl*{4}c @{}}
        & & \multicolumn{4}{c}{} \\[2ex]
        & & \rot{has framework}
          & \rot{\shortstack[l]{problem-independent\\constraints}}
          & \rot{supports x}
          & \rot{supports x} \\
        \cmidrule{2-6}
        & mlpack             & \CIRCLE & \CIRCLE & \CIRCLE & \CIRCLE  \\
        & vowpal wabbit      &  - & - & -  & -  \\
        & TensorFlow         &  - & -  & -  & -  \\
        & scikit-learn       &  - & -  & -  & - \\
        & scipy              &  - & \LEFTcircle  & \LEFTcircle  & \LEFTcircle \\
        \cmidrule[1pt]{2-6}
    \end{tabular}
    \begin{tablenotes}\footnotesize
\item[*] Library feature comparison: \CIRCLE=\text{provides feature}, \LEFTcircle=\text{partially provides feature}, -=\text{does not provide feature}
\end{tablenotes}
\end{table}

\section{mlpack: a scalable C++ machine learning library}

\begin{itemize}
  \item Some quick background on what mlpack is and what its goals are.
Probably the list of four goals is good here (though maybe not in itemized
format).
  \item Discuss why we've chosen C++, and how policy-based design gives us some
really nice flexibility.  (Maybe there is not fully space for that.)
\end{itemize}

\section{Requirements for optimizers and functions}

In general, we want to be able to consider any solver of the problem

\begin{equation}
\operatorname{argmin}_{x} f(x)
\end{equation}

\noindent for any function $f(x)$ that takes some vector input $x$.  However, it
is impossible to implement something both so generic and fast---for instance,
gradient-based approaches converge far more quickly than gradient-free
approaches (in general), so we must design an abstraction that is able to
simultaneously generalize to many problem types, as well as able to take
advantage of accelerations and optimizations.

Let us split the class of functions to be optimized into some subclasses:

\begin{itemize}
  \item {\bf arbitrary}: no assumptions can be made on $f(x)$
  \item {\bf differentiable}: $f(x)$ has a computable gradient $f'(x)$
  \item {\bf separable}: $f(x)$ is a sum of individual components: $f(x) =
\sum_{i} f_i(x)$
  \item {\bf categorical}: $x$ contains elements that can only take discrete
values
  \item {\bf numeric}: all elements of $x$ take values in $\mathcal{R}$
  \item {\bf sparse}: the gradient $f'(x)$ or $f_i(x)$ (for a separable
function) is sparse
  \item {\bf partially differentiable}: the gradient $f'_j(x)$ is computable for
individual elements $x_j$ of $x$
  \item {\bf bounded}: $x$ is limited in the values that it can take
\end{itemize}

Needless to say, it is impossible to create a system where every optimizer can
work with every possible type of function: a gradient-based optimizer cannot
reasonably be expected to work with an arbitrary function $f(x)$ where the
gradient is not computable or available.

Instead, the best we can hope to achieve is to maximize the flexibility
available, so that a user can easily implement a function $f(x)$ and have it
work with as many optimizers as possible.  For this, C++ policy-based design
aids us greatly: when implementing a function to be optimized, a user can
implement only a few methods and we can use C++ template metaprogramming to
check that the given functions match the requirements of the optimizer that is
being used.  When implementing an optimizer, a user can assume that the given
function to be optimized meets the required assumptions of the optimizers, and
encode those requirements.  Since we are using templates and C++, the resulting
code generated by the compiler can be identical to what a developer would write
if they were writing an optimizer specifically for the function $f(x)$ at
hand---this can provide significant efficiency gains.

{\bf <TODO: maybe we should add a table with optimizer types that work with
certain assumptions.  Maybe this can be a table, maybe a diagram, but some kind
of visual aid to split the space of objective function types would be nice.>}

\section{{\tt FunctionType} API}

In order to facilitate consistent implementations, we have defined a {\tt
FunctionType} API that describes all the functions that an objective function
may (or must) implement, depending on the subclass of objective function.

{\bf <TODO: we can add a list of each function and what it does.  A basic list
is below.  We can elaborate on this significantly.>}

\begin{itemize}
  \item {\tt Evaluate()}
  \item {\tt Gradient()}
  \item {\tt PartialGradient()} 
  \item ...
  \item constraints?
  \item discrete variable support?
  \item batch support
\end{itemize}

A user may implement as many (or as few) of these functions as they would like,
and this will allow them to use a larger set of optimizers.

{\bf <TODO: add very simple example function>}


For instance, the code below defines a simple sparse function, where each
dimension has a parabola with a distinct minimum.

\begin{lstlisting}
class SparseFunction
{
  SparseFunction()
  {
    intercepts = arma::vec("20 12 15 100");
    bi = arma::vec("-4 -2 -3 -8");
  }

  double Evaluate(const arma::mat& p, const size_t i)
  {
    return p[i] * p[i] + bi[i] * p[i] + intercepts[i];
  }

  void Gradient(const arma::mat& p, const size_t i, arma::sp_mat& g)
  {
    g.zeros(arma::size(p));
    g[i] = 2 * p[i] + bi[i];
  }
}

\end{lstlisting}

Another important component of the optimization framework design is flexibility. To this end, we use a C++ programming paradigm known as policy-based design \cite{Alexandrescu2001}. In short, this means that the behavior is easily controllable by the user, simply by specifying template parameters. For example, the SGD class, which is used as basis for other stochastic gradient descent methods, accepts a template parameter UpdateType. Thus, if the user wants to update the learning rate update strategy that mlpack does not have support for, they merely need to implement a optimizer class, and then they can use the type SGD<MyCustomLearningRate>. Additionally, because templates are being used, there is no additional overhead, as there would be when providing this type of support through inheritance or in other languages such as Python or C

\section{Static checking of functions}

{\bf <TODO: probably a better section title>}

Unfortunately, template metaprogramming can result in some very lengthy error
messages.  Therefore, we must be careful to ensure that a user is able to easily
debug a problem when they implement an objective function or gradient.  To
provide good error message output, we can use C++'s template metaprogramming
support to determine what methods a type has available.  Similarly, we can also
use static compile-time constants to denote the methods that are require by a
specific optimizer.  This is implemented via SFINAE \cite{sfinae}.  A {\tt
static\_assert()} is raised when a given objective function does not have the
required methods for a given optimizer.  {\bf <TODO: implement this, so we are
not lying.  But it should be easy enough, maybe an hour of work max.>}

For instance, when attempting to use the L-BFGS optimizer without having a
{\tt Gradient()} function implemented, the user will receive the following error
message:

{\bf <TODO: put error message here.  If we are short on space, let's cut this
example and make this section shorter.>}

\section{Supported optimizers and functions in mlpack}

Thanks to the easy abstraction, we have been able to provide support for a large
set of diverse optimizers and objective functions.  Below is a list of what is
currently available.

% I guess to save some space we should group them.
\begin{itemize}
  \item {\bf SGD variants:} Stochastic Gradient Descent (SGD), Stochastic
      Coordinate Descent (SCD), Parallel Stochastic Gradient Descent (Hogwild!),
      Stochastic Gradient Descent with Restarts (SGDR), SMORMS3, AdaGrad,
      AdaDelta, RMSProp, Adam, AdaMax

  \item {\bf Quasi-Newton variants:} Limited-memory BFGS (L-BFGS), incremental
        Quasi-Newton method (IQN), Augmented Lagrangian Method

  \item {\bf Genetic variants:} Conventional Neuro-evolution (CNE), Covariance
        Matrix Adaptation Evolution Strategy (CMA-ES)

  \item {\bf Annealing variants:} Simulated Annealing

  \item {\bf Else:} Conditional Gradient Descent (Frank-Wolfe algorithm)

  \item {\bf Objective functions:} Neural Networks, Logistic regression,
      Matrix completion, Neighborhood Components Analysis, Regularized SVD,
      Reinforcement learning, Softmax regression, Sparse autoencoders,
      Sparse SVM
\end{itemize}

In addition, many methods are currently in development and will be released in
the future.

\section{Conclusion}

We have identified that the support for generic and robust optimization is not
currently available in most machine learning toolkits, and acted upon this
observation to provide an easy framework for both implementing new optimizers
and new objective functions to be optimized inside of the {\bf mlpack} machine
learning library.  This supports a 

\bibliographystyle{plain}
\bibliography{paper}

\end{document}
